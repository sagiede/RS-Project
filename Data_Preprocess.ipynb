{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose Dataset to Extract Feautres\n",
    "\n",
    "# data_to_preprocess = 'amazon_video_games'\n",
    "# data_to_preprocess = 'amazon_movies'\n",
    "data_to_preprocess = 'movielens1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/modules/packages/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # # # # Amazon Video Games\n",
    "if data_to_preprocess == 'amazon_video_games':\n",
    "    ratings_df = pd.read_json('data/reviews_Video_Games.json', lines=True)\n",
    "    data_path = 'data/amazon_video_games'\n",
    "    user_column = 'reviewerID'\n",
    "    item_column = 'asin'\n",
    "    rating_column = 'overall'\n",
    "\n",
    "# # # # # Amazon Tv & Movies\n",
    "if data_to_preprocess == 'amazon_movies':\n",
    "    ratings_df = pd.read_json('data/reviews_Movies_and_TV.json', lines=True)\n",
    "    data_path = 'data/amazon_movies'\n",
    "    user_column = 'reviewerID'\n",
    "    item_column = 'asin'\n",
    "    rating_column = 'overall'\n",
    "    \n",
    "# # # # # MovieLense 1m\n",
    "if data_to_preprocess == 'movielens1m':\n",
    "    ratings_df = pd.read_csv('data/ml-1m/ratings.dat', sep='::', names=['user', 'item', 'rating', 'time'])\n",
    "    data_path = 'data/ml-1m'\n",
    "    user_column = 'user'\n",
    "    item_column = 'item'\n",
    "    rating_column = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ratings_df(min_interactions, ratings_df, key_column):\n",
    "    \n",
    "    filtered_df = []\n",
    "    for _, df in ratings_df.groupby(key_column):\n",
    "        if len(df) < min_interactions:\n",
    "            continue\n",
    "        filtered_df.append(df)\n",
    "    ratings_df = pd.concat(filtered_df)\n",
    "    return ratings_df\n",
    "\n",
    "\n",
    "if data_to_preprocess == 'amazon_movies' or data_to_preprocess == 'amazon_video_games': \n",
    "    ratings_df = filter_ratings_df(10, ratings_df, user_column)\n",
    "    ratings_df = filter_ratings_df(7, ratings_df, item_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ids to indeces map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = ratings_df[user_column].unique()\n",
    "unique_item_ids = ratings_df[item_column].unique()\n",
    "\n",
    "users_map = {}\n",
    "for idx, user_id in enumerate(unique_user_ids):\n",
    "    users_map[user_id] = idx\n",
    "\n",
    "items_map = {}\n",
    "for idx, item_id in enumerate(unique_item_ids):\n",
    "    items_map[item_id] = idx\n",
    "    \n",
    "users_map = {str(k):v for k,v in users_map.items()}\n",
    "items_map = {str(k):v for k,v in items_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(key_column):\n",
    "    train_df = []\n",
    "    test_df = []\n",
    "    for key, key_df in ratings_df.groupby(key_column):\n",
    "        key_test_df = key_df.sample(frac=0.1, random_state=3)\n",
    "        key_train_df = key_df.loc[~key_df.index.isin(key_test_df.index)]\n",
    "\n",
    "        train_df.append(key_train_df)\n",
    "        test_df.append(key_test_df)\n",
    "\n",
    "    train_df = pd.concat(train_df)\n",
    "    test_df = pd.concat(test_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "u_train_ratings_df, u_test_ratings_df = split_train_test(key_column=user_column)\n",
    "i_train_ratings_df, i_test_ratings_df = split_train_test(key_column=item_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Numpy ratings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(unique_user_ids)\n",
    "n_items = len(unique_item_ids)\n",
    "\n",
    "def create_table(ratings_df):\n",
    "    ratings_table = np.zeros([n_users, n_items])\n",
    "    for user, user_df in ratings_df.groupby([user_column]):\n",
    "        user_idx = users_map[str(user)]\n",
    "        for _, item_row in user_df.iterrows():\n",
    "            item_idx = items_map[str(item_row[item_column])]\n",
    "            ratings_table[user_idx, item_idx] = item_row[rating_column]\n",
    "    return ratings_table\n",
    "\n",
    "users_ratings_table_train = create_table(u_train_ratings_df)\n",
    "items_ratings_table_train = create_table(i_train_ratings_df)\n",
    "items_ratings_table_train = items_ratings_table_train.transpose()\n",
    "\n",
    "users_ratings_table_test = create_table(u_test_ratings_df)\n",
    "items_ratings_table_test = create_table(i_test_ratings_df)\n",
    "items_ratings_table_test = items_ratings_table_test.transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data for model use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(f'{data_path}/users_ratings_table_train.npy', users_ratings_table_train)\n",
    "np.save(f'{data_path}/users_ratings_table_test.npy', users_ratings_table_test)\n",
    "\n",
    "np.save(f'{data_path}/items_ratings_table_train.npy', items_ratings_table_train)\n",
    "np.save(f'{data_path}/items_ratings_table_test.npy', items_ratings_table_test)\n",
    "\n",
    "u_train_ratings_df.to_csv(f'{data_path}/u_train_df.csv' ,index=False)\n",
    "i_train_ratings_df.to_csv(f'{data_path}/i_train_df.csv' ,index=False)\n",
    "\n",
    "\n",
    "with open(f'{data_path}/users_map.json', 'w') as f:\n",
    "    json.dump(users_map, f)\n",
    "    \n",
    "with open(f'{data_path}/items_map.json', 'w') as f:\n",
    "    json.dump(items_map, f)\n",
    "    \n",
    "# d = np.load('users_text_vectors.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ColdEvaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crate_coldeval_test(train_table, test_table):\n",
    "    train_interactions_count = (train_table > 0).sum(axis=1)\n",
    "    rows_mask = (train_interactions_count > np.median(train_interactions_count)) # rows_mask = True on TOP 50% POPULAR ITEMS\n",
    "    test_table[rows_mask] = np.zeros(test_table.shape[1])\n",
    "    return test_table\n",
    "\n",
    "users_ratings_table_test = crate_coldeval_test(users_ratings_table_train, users_ratings_table_test)\n",
    "items_ratings_table_test = crate_coldeval_test(items_ratings_table_train, items_ratings_table_test)\n",
    "\n",
    "np.save(f'{data_path}/users_ratings_table_cold_test.npy', users_ratings_table_test)\n",
    "np.save(f'{data_path}/items_ratings_table_cold_test.npy', items_ratings_table_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popular based expereiment\n",
    "\n",
    "Guess Rating_prediction based on each item mean rating in train (un personalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(items_table_train, users_table_test):\n",
    "    items_baseline_preds = []\n",
    "\n",
    "    for item_row in  items_table_train:\n",
    "        items_baseline_preds.append(item_row[np.nonzero(item_row)[0]].mean())\n",
    "    items_baseline_preds = np.array(items_baseline_preds)\n",
    "\n",
    "    items_baseline_preds\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    for user_row in users_table_test:\n",
    "        test_indeces = np.nonzero(user_row)\n",
    "        if test_indeces:\n",
    "            for test_index in test_indeces[0]: \n",
    "                y_true = user_row[test_index]\n",
    "                y_pred = items_baseline_preds[test_index]\n",
    "                all_y_true.append(y_true)\n",
    "                all_y_pred.append(y_pred)\n",
    "\n",
    "    all_y_pred = np.array(all_y_pred)\n",
    "    all_y_true = np.array(all_y_true)\n",
    "\n",
    "\n",
    "    rmse = np.sqrt(((all_y_pred - all_y_true) ** 2).mean())\n",
    "    mae = np.abs(all_y_pred - all_y_true).mean()\n",
    "\n",
    "    print(f'{data_to_preprocess} Data Experiment')\n",
    "    print('RMSE Popularity Baseline Expr: ', rmse)\n",
    "    print('MAE Popularity Baseline Expr: ', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Baseline Results:\n",
      "\n",
      " Amazon_video_games Experiment Regular\n",
      "movielens1m Data Experiment\n",
      "RMSE Popularity Baseline Expr:  1.0452992816384392\n",
      "MAE Popularity Baseline Expr:  0.8093617782200861\n",
      "\n",
      "\n",
      " Amazon_video_games Experiment ColdEvaluation\n",
      "movielens1m Data Experiment\n",
      "RMSE Popularity Baseline Expr:  1.054362034428959\n",
      "MAE Popularity Baseline Expr:  0.8199518171271164\n",
      "\n",
      "\\n Movielens 1m Experiment Regular\n",
      "movielens1m Data Experiment\n",
      "RMSE Popularity Baseline Expr:  0.9744565539385563\n",
      "MAE Popularity Baseline Expr:  0.7782834928034735\n",
      "\n",
      "\n",
      " Movielens 1m Experiment ColdEvaluation\n",
      "movielens1m Data Experiment\n",
      "RMSE Popularity Baseline Expr:  1.0046994940246092\n",
      "MAE Popularity Baseline Expr:  0.8052622831873744\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/amazon_video_games'\n",
    "\n",
    "print('\\nAll Baseline Results:')\n",
    "\n",
    "items_table_train = np.load(f'{data_path}/items_ratings_table_train.npy', allow_pickle=True)\n",
    "\n",
    "users_table_test = np.load(f'{data_path}/users_ratings_table_test.npy', allow_pickle=True)\n",
    "print('\\n Amazon_video_games Experiment Regular')\n",
    "run_experiment(items_table_train, users_table_test)\n",
    "\n",
    "users_table_test = np.load(f'{data_path}/users_ratings_table_cold_test.npy', allow_pickle=True)\n",
    "print('\\n\\n Amazon_video_games Experiment ColdEvaluation')\n",
    "run_experiment(items_table_train, users_table_test)\n",
    "\n",
    "data_path = 'data/ml-1m'\n",
    "items_table_train = np.load(f'{data_path}/items_ratings_table_train.npy', allow_pickle=True)\n",
    "\n",
    "users_table_test = np.load(f'{data_path}/users_ratings_table_test.npy', allow_pickle=True)\n",
    "print('\\n\\\\n Movielens 1m Experiment Regular')\n",
    "run_experiment(items_table_train, users_table_test)\n",
    "\n",
    "users_table_test = np.load(f'{data_path}/users_ratings_table_cold_test.npy', allow_pickle=True)\n",
    "print('\\n\\n Movielens 1m Experiment ColdEvaluation')\n",
    "run_experiment(items_table_train, users_table_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
